## Title of the Project
Empathetic Chatbot for Emotion Recognition and Tone Mirroring

## Small description about the project like one below
The development of an empathetic chatbot aimed at understanding user emotions from speech and text input and responding with emotionally appropriate, tone-mirrored replies to enhance human–computer interaction.

## About
The Empathetic Chatbot for Emotion Recognition and Tone Mirroring is a conversational AI system designed to identify the emotional state of users and generate empathetic responses accordingly. Traditional chatbots focus mainly on providing factual or task-oriented responses and often fail to consider the emotional context of user interactions. This project addresses that limitation by integrating speech recognition, emotion detection, and controlled response generation into a single unified framework.

The chatbot uses advanced deep learning and natural language processing techniques to transcribe speech input, detect emotions such as sadness, joy, anger, fear, surprise, and love, and generate emotionally aligned responses. The system provides a user-friendly interface that supports real-time interaction, making it suitable for applications such as mental health support, education, customer service, and virtual companionship.

## Features
Implements transformer-based deep learning models
Supports both speech and text-based interaction
Real-time emotion recognition and response generation
Emotion-aware prompt engineering for tone control
Framework-based application suitable for deployment
High scalability and modular system architecture
Low response latency for real-time use

## Requirements
<!--List the requirements of the project as shown below-->
* Operating System: Requires a 64-bit OS (Windows 10 or Ubuntu) for compatibility with deep learning frameworks.
* Development Environment: Python 3.6 or later is necessary for coding the sign language detection system.
* Deep Learning Frameworks: TensorFlow for model training, MediaPipe for hand gesture recognition.
* Image Processing Libraries: OpenCV is essential for efficient image processing and real-time hand gesture recognition.
* Version Control: Implementation of Git for collaborative development and effective code management.
* IDE: Use of VSCode as the Integrated Development Environment for coding, debugging, and version control integration.
* Additional Dependencies: Includes scikit-learn, TensorFlow (versions 2.4.1), TensorFlow GPU, OpenCV, and Mediapipe for deep learning tasks.

## System Architecture

![WhatsApp Image 2025-12-25 at 9 31 29 PM](https://github.com/user-attachments/assets/49e4b788-c5ac-4599-9555-be7d887cee95)


## Output

<img width="1280" height="593" alt="image" src="https://github.com/user-attachments/assets/54bf23a6-b13f-4a17-98d6-4db9b684c0d2" />


#### Output1 - Name of the output

<img width="1280" height="596" alt="image" src="https://github.com/user-attachments/assets/675a72cc-5183-481a-af6c-200b857bd00c" />


## Results and Impact
The Empathetic Chatbot enhances the quality of human–computer interaction by incorporating emotional intelligence into conversational systems. By understanding and responding to user emotions, the chatbot provides more natural, supportive, and engaging conversations compared to traditional chatbots.

The project demonstrates the effective integration of speech recognition, emotion detection, and transformer-based response generation, showcasing the potential of empathetic AI systems in real-world applications. This work serves as a foundation for future advancements in emotionally intelligent virtual assistants and human-centered AI systems.

## Articles published / References
```
1.R. Picard, Affective Computing, MIT Press, 1997.
2. Vaswani et al., “Attention Is All You Need,” NeurIPS, 2017.
3. Radford et al., “Language Models are Unsupervised Multitask Learners,” OpenAI, 2019.
4.OpenAI, “Whisper: Robust Speech Recognition via Large-Scale Weak Supervision,” 2022.
5.Hugging Face, “Transformers: State-of-the-Art Natural Language Processing,” 2020.
```
